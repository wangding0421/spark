{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Definition of some global parameters.\n",
    "K = 5  # Number of centroids\n",
    "RUNS = 25  # Number of K-means runs that are executed in parallel. Equivalently, number of sets of initial points\n",
    "RANDOM_SEED = 60295531\n",
    "converge_dist = 0.1 # The K-means algorithm is terminated when the change in the location \n",
    "                    # of the centroids is smaller than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "\n",
    "def print_log(s):\n",
    "    sys.stdout.write(s + \"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def parse_data(row):\n",
    "    '''\n",
    "    Parse each pandas row into a tuple of (station_name, feature_vec),\n",
    "    where feature_vec is the concatenation of the projection vectors\n",
    "    of TAVG, TRANGE, and SNWD.\n",
    "    '''\n",
    "    return (row[0], np.concatenate([row[1], row[2], row[3]]))\n",
    "    # change the input data into the form (station_name, feature_vec)\n",
    "\n",
    "\n",
    "def compute_entropy(d):\n",
    "    '''\n",
    "    Compute the entropy given the frequency vector `d`\n",
    "    '''\n",
    "    d = np.array(d)\n",
    "    d = 1.0 * d / d.sum()\n",
    "    return -np.sum(d * np.log2(d))\n",
    "\n",
    "\n",
    "def choice(p):\n",
    "    '''\n",
    "    Generates a random sample from [0, len(p)),\n",
    "    where p[i] is the probability associated with i. \n",
    "    So here p is a vector, p[0],p[1],...,p[n-1]\n",
    "    '''\n",
    "    random = np.random.random()  # gives a random value between (0,1)\n",
    "    r = 0.0\n",
    "    for idx in range(len(p)):\n",
    "        r = r + p[idx]\n",
    "        if r > random:\n",
    "            return idx \n",
    "            # here return the index of the data where indices smaller than this with prob \n",
    "            # larger than random\n",
    "    assert(False)\n",
    "\n",
    "\n",
    "def kmeans_init(rdd, K, RUNS, seed):\n",
    "    '''\n",
    "    Select `RUNS` sets of initial points for `K`-means++\n",
    "    '''\n",
    "    # the `centers` variable is what we want to return\n",
    "    \n",
    "    n_data = rdd.count()\n",
    "    shape = rdd.take(1)[0][1].shape[0]\n",
    "    \n",
    "    # rdd.take(1) is a tuple (station_name, feature_vec), and we need the dimension of the \n",
    "    # feature_vec since it is also the dimension of the centers. \n",
    "    \n",
    "    centers = np.zeros((RUNS, K, shape)) \n",
    "    # RUNS record the run round and centers record every update from Round-1 to Round-RUNS.\n",
    "    \n",
    "    def update_dist(vec, dist, k):\n",
    "        new_dist = norm(vec - centers[:, k], axis=1)**2\n",
    "        return np.min([dist, new_dist], axis=0)\n",
    "\n",
    "\n",
    "    # The second element `dist` in the tuple below is the closest distance from\n",
    "    # each data point to the selected points in the initial set, where `dist[i]`\n",
    "    # is the closest distance to the points in the i-th initial set. where i belongs to \n",
    "    # (0,1,2,...,RUNS-1)\n",
    "    \n",
    "    data = rdd.map(lambda p: (p, [np.inf] * RUNS)).cache()\n",
    "    # Let the initial distance at all rounds to be inf, and update each round\n",
    "\n",
    "    # Collect the feature vectors of all data points beforehand, might be\n",
    "    # useful in the following for-loop\n",
    "    \n",
    "    local_data = rdd.map(lambda (name, vec): vec).collect()\n",
    "\n",
    "    # Randomly select the first point for every run of k-means++,\n",
    "    # i.e. randomly select `RUNS` points and add it to the `centers` variable\n",
    "    \n",
    "    sample = [local_data[k] for k in np.random.randint(0, len(local_data), RUNS)]\n",
    "    centers[:, 0] = sample\n",
    "    \n",
    "    D = (np.inf)*np.ones((RUNS,n_data)) # my code\n",
    "    \n",
    "    for idx in range(K - 1):\n",
    "        ##############################################################################\n",
    "        # Insert your code here:\n",
    "        ##############################################################################\n",
    "        # In each iteration, you need to select one point for each set\n",
    "        # of initial points (so select `RUNS` points in total).\n",
    "        # For each data point x, let D_i(x) be the distance between x and\n",
    "        # the nearest center that has already been added to the i-th set.\n",
    "        # Choose a new data point for i-th set using a weighted probability\n",
    "        # where point x is chosen with probability proportional to D_i(x)^2\n",
    "        ##############################################################################\n",
    "        #--------------------   My code starts -------------------------\n",
    "        D = np.array([update_dist(vec,D[:,x],idx) for x, vec in enumerate(local_data)]).T  \n",
    "        prob = ((D.T)/D.sum(axis=1)).T                                                  \n",
    "        for i in range(RUNS):                                         \n",
    "            ind = choice(prob[i])\n",
    "            centers[i,idx+1,:] = local_data[ind]\n",
    "        #--------------------   My code ends ---------------------------\n",
    "    return centers\n",
    "\n",
    "\n",
    "def get_closest(p, centers):\n",
    "    '''\n",
    "    Return the indices the nearest centroids of `p`.\n",
    "    `centers` contains sets of centroids, where `centers[i]` is\n",
    "    the i-th set of centroids.\n",
    "    '''\n",
    "    best = [0] * len(centers)    # len(centers) = RUNS\n",
    "    closest = [np.inf] * len(centers)\n",
    "    for idx in range(len(centers)):    # idx = 0,1,2,...,RUNS-1\n",
    "        for j in range(len(centers[0])):   # j = 0,1,2,...,K-1\n",
    "            temp_dist = norm(p - centers[idx][j])\n",
    "            if temp_dist < closest[idx]:\n",
    "                closest[idx] = temp_dist\n",
    "                best[idx] = j\n",
    "    return best  # best is a 1*RUNS array, contains the group index of a given vector p\n",
    "\n",
    "\n",
    "def kmeans(rdd, K, RUNS, converge_dist, seed):\n",
    "    '''\n",
    "    Run K-means++ algorithm on `rdd`, where `RUNS` is the number of\n",
    "    initial sets to use.\n",
    "    '''\n",
    "    k_points = kmeans_init(rdd, K, RUNS, seed)\n",
    "    print_log(\"Initialized.\")\n",
    "    temp_dist = 1.0\n",
    "\n",
    "    iters = 0\n",
    "    st = time.time()\n",
    "    while temp_dist > converge_dist:\n",
    "        ##############################################################################\n",
    "        # INSERT YOUR CODE HERE\n",
    "        local_data = rdd.map(lambda (name, vec): vec).collect()\n",
    "        ##############################################################################\n",
    "        \n",
    "        # Update all `RUNS` sets of centroids using standard k-means algorithm\n",
    "        # Outline:\n",
    "        #   - For each point x, select its nearest centroid in i-th centroids set\n",
    "        #   - Average all points that are assigned to the same centroid\n",
    "        #   - Update the centroid with the average of all points that are assigned to it\n",
    "        \n",
    "        # Insert your code here\n",
    "        B = np.array([get_closest(vec,k_points) for vec in local_data]).T  \n",
    "        \n",
    "        \n",
    "        #  \n",
    "        # new_points = new centers\n",
    "        \n",
    "\n",
    "\n",
    "        # You can modify this statement as long as `temp_dist` equals to\n",
    "        # max( sum( l2_norm of the movement of j-th centroid in each centroids set ))\n",
    "        \n",
    "        ##############################################################################\n",
    "\n",
    "        temp_dist = np.max([\n",
    "                np.sum([norm(k_points[idx][j] - new_points[(idx, j)]) for j in range(K)])\n",
    "                    for idx in range(RUNS)])\n",
    "\n",
    "        iters = iters + 1\n",
    "        if iters % 5 == 0:\n",
    "            print_log(\"Iteration %d max shift: %.2f (time: %.2f)\" %\n",
    "                      (iters, temp_dist, time.time() - st))\n",
    "            st = time.time()\n",
    "\n",
    "        # update old centroids\n",
    "        # You modify this for-loop to meet your need\n",
    "        for ((idx, j), p) in new_points.items():\n",
    "            # Finally let k_points = new_points\n",
    "            k_points[idx][j] = p\n",
    "\n",
    "    return k_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'USC00044534', array([  3.04796236e+03,   1.97434852e+03,   1.50560792e+02,\n",
       "          -2.90363288e+03,  -2.36907268e+02,   1.47021791e+02,\n",
       "           1.91503001e-01,   1.87262808e-01,  -4.01379553e-02]))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pickle.load(open(\"./stations_projections.pickle\", \"rb\"))\n",
    "rdd = sc.parallelize([parse_data(row[1]) for row in data.iterrows()])\n",
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 5, 9)\n",
      "Time takes to converge: 1.78669595718\n"
     ]
    }
   ],
   "source": [
    "# This cell test if the initialization function works\n",
    "import time\n",
    "st = time.time()\n",
    "center = kmeans_init(rdd, K, RUNS, seed)\n",
    "print np.shape(center)\n",
    "print \"Time takes to converge:\", time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1.49010782e+03   1.94542355e+03   1.53683044e+02 ...,   2.20539692e+02\n",
      "     1.22748994e+02   4.13202539e+01]\n",
      "  [  6.36495448e+02   1.13508697e+03   1.58627087e+00 ...,   3.76151648e+04\n",
      "    -1.35560407e+04   4.05190927e+03]\n",
      "  [  2.45777109e+03   1.91940921e+03   8.62422512e+01 ...,   1.87438742e+01\n",
      "     8.82612480e-01   1.69554224e+00]\n",
      "  [  4.51056147e+02   2.00082895e+03  -6.13059147e+01 ...,   1.05829752e+04\n",
      "    -9.02142671e+02   6.00534013e+02]\n",
      "  [ -1.19636689e+01   1.64470736e+03  -1.79876514e+01 ...,   5.89415987e+03\n",
      "    -1.12248908e+03   3.35610514e+02]]\n",
      "\n",
      " [[  2.23643114e+03   1.95170147e+03  -3.61944620e+01 ...,   6.34745555e+01\n",
      "     2.10312468e+01  -2.76628330e+00]\n",
      "  [  1.00620820e+03   1.51910127e+03   1.02186191e+02 ...,   7.31306416e+03\n",
      "    -7.29344006e+01   2.39440682e+01]\n",
      "  [  2.12907689e+03   1.39902211e+03   1.12658115e+02 ...,   6.49062252e+00\n",
      "     2.78814746e+00   2.94524554e+00]\n",
      "  [  3.79211741e+02   2.41464461e+03   9.62494430e+01 ...,   1.77513598e+03\n",
      "     2.45685554e+02   7.41967778e+01]\n",
      "  [  4.77407578e+02   1.24797600e+03   1.04493669e+02 ...,   2.39277044e+04\n",
      "    -6.89845024e+03   2.42998018e+03]]\n",
      "\n",
      " [[  1.77917284e+03   2.29614419e+03   7.52235567e+01 ...,   3.25299356e+02\n",
      "     1.05755495e+02   9.68318817e+01]\n",
      "  [  3.59619977e+02   1.49067642e+03   9.41540149e+01 ...,   2.21878818e+04\n",
      "    -6.72839268e+03   2.75422121e+03]\n",
      "  [  2.42231008e+01   1.52235303e+03   8.58670182e+01 ...,   6.69992722e+03\n",
      "    -1.62178959e+03   3.44832044e+02]\n",
      "  [  4.09498140e+03   1.83404463e+03   8.47543231e+01 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  4.23718542e+02   1.02090491e+03   2.69105936e+01 ...,   3.85449811e+04\n",
      "    -1.39061241e+04   4.52291550e+03]]\n",
      "\n",
      " ..., \n",
      " [[  3.03816307e+03   1.96205872e+03   9.74890314e+01 ...,   3.78613377e+00\n",
      "     2.95746260e+00   1.69101058e-01]\n",
      "  [  6.64359697e+02   1.32361981e+03  -4.36473642e+01 ...,   2.05797523e+04\n",
      "    -5.30008935e+03  -6.47940812e+01]\n",
      "  [ -1.18530537e+01   1.42436731e+03   1.21238782e+02 ...,   7.19329597e+03\n",
      "     9.27072552e+01   8.19985621e+02]\n",
      "  [  2.94138146e+03   1.51337030e+03  -2.45931469e+01 ...,   4.63817847e-01\n",
      "     4.22149802e-01  -1.24381080e-01]\n",
      "  [  6.86330799e+02   2.25679074e+03  -5.46931913e+01 ...,   2.32064826e+03\n",
      "    -6.90106331e+01   2.77367867e+02]]\n",
      "\n",
      " [[  4.26223030e+02   2.16113054e+03  -5.94715627e+01 ...,   2.43454100e+03\n",
      "    -2.44811836e+02   1.00921121e+02]\n",
      "  [  2.67459975e+03   1.95691804e+03   1.22815026e+02 ...,   1.53764649e+01\n",
      "     5.45790693e+00  -8.09462329e-01]\n",
      "  [  1.19068868e+03   1.77238029e+03   2.10322250e+02 ...,   3.52436569e+02\n",
      "     1.83400659e+02   4.89001769e+01]\n",
      "  [  4.23718542e+02   1.02090491e+03   2.69105936e+01 ...,   3.85449811e+04\n",
      "    -1.39061241e+04   4.52291550e+03]\n",
      "  [  8.42409816e+02   1.13168513e+03   4.72811824e+01 ...,   1.10674976e+04\n",
      "    -1.89230379e+03   1.13792581e+03]]\n",
      "\n",
      " [[  3.06580951e+03   1.87436416e+03   4.76513434e+01 ...,   7.07457694e+00\n",
      "     5.80403531e+00  -1.98370677e+00]\n",
      "  [  1.06069520e+03   1.62395030e+03   1.54322631e+02 ...,   2.49251123e+03\n",
      "     6.20031688e+02   1.19603319e+02]\n",
      "  [  6.64359697e+02   1.32361981e+03  -4.36473642e+01 ...,   2.05797523e+04\n",
      "    -5.30008935e+03  -6.47940812e+01]\n",
      "  [  4.41062202e+02   1.59136949e+03   2.72206643e+00 ...,   5.57086832e+03\n",
      "    -2.20522777e+01   7.58779886e+01]\n",
      "  [  8.69762445e+02   2.06342537e+03   9.76278183e+01 ...,   3.53519816e+02\n",
      "     8.83356321e+01   1.01639939e+02]]]\n"
     ]
    }
   ],
   "source": [
    "# This cell test if the initialization function works\n",
    "print center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 5, 9)\n",
      "25\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "centers = np.array(center)\n",
    "print np.shape(centers)\n",
    "print len(centers)\n",
    "print len(centers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
